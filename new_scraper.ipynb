{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional WebScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import re\n",
    "\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', (element).encode('utf-8')):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "htmls = ['https://www.sec.gov/Archives/edgar/data/1065280/000119312508040378/d10k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000119312509037430/d10k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000119312510036181/d10k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000119312511040217/d10k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000119312512053009/d260328d10k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000106528013000008/nflx1231201210kdoc.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000106528014000006/nflx10k2013.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000106528015000006/nflx201410k.htm',\n",
    "          'https://www.sec.gov/Archives/edgar/data/1065280/000106528016000047/nflx201510k.htm'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1B on year 2015 has zero length!!!\n",
      "Section 9B on year 2015 has zero length!!!\n"
     ]
    }
   ],
   "source": [
    "errors = pd.DataFrame(columns=['id', 'year', 'section', 'comment'])\n",
    "logs = pd.DataFrame(columns=['id', 'year', 'section', 'pre_length', 'length', 'pct_length'])\n",
    "htmls = ['https://www.sec.gov/Archives/edgar/data/37996/000003799616000092/f1231201510-k.htm']\n",
    "\n",
    "all_docs = {}\n",
    "\n",
    "for html in htmls:\n",
    "    all_sections = {}\n",
    "    soup = BeautifulSoup(urllib2.urlopen(html).read(), 'html.parser')\n",
    "    \n",
    "    ## Extract visible text.\n",
    "    texts = soup.findAll(text=True)\n",
    "    visible_texts = filter(visible, texts)\n",
    "    len_total = len(visible_texts)\n",
    "    \n",
    "    ## Extract year and id.\n",
    "    doc_id = html.split('/')[6]\n",
    "    pattern_year = re.compile('\\d{2}, \\d{4}.*')\n",
    "    year = [line for line in visible_texts if pattern_year.findall(line)][0].split(',')[-1].strip()\n",
    "    \n",
    "    ## Log error and skip document if year is wrong.\n",
    "    if len(year) != 4:\n",
    "        print 'Year incorrectly defined! Skipping document.'\n",
    "        errors.loc[len(errors)] = [doc_id, year, 'all', 'invalid year format']\n",
    "        continue\n",
    "    \n",
    "    ## List all available sections.\n",
    "    sections = ['1', '1A', '1B', '2', '3', '4', '5', '6', '7', '7A', \\\n",
    "                '8', '9', '9A', '9B', '10', '11', '12', '13', '14', '15']\n",
    "    \n",
    "    for i in range(len(sections)-1):\n",
    "        ## Starting and ending lines for section.\n",
    "        pattern_start = re.compile(\"(\\s)?Item[(\\\\xa0)|(\\s)]?\" + sections[i] + \"\\.\", re.I)\n",
    "        pattern_end = re.compile(\"(\\s)?Item[(\\\\xa0)|(\\s)]?\" + sections[i+1] + \"\\.\", re.I)\n",
    "\n",
    "        ## Get the start and end headers, and make sure they are exactly 2.\n",
    "        start = [[s,line] for s,line in enumerate(visible_texts) if pattern_start.match(line)]\n",
    "        end = [[e,line] for e,line in enumerate(visible_texts) if pattern_end.match(line)]\n",
    "        \n",
    "        ## If we extracted more than 1 item for each header, ignore the TOC one.\n",
    "        if len(start) >1 and len(end) > 1:\n",
    "            start = [start[1]]\n",
    "            end = [end[1]]\n",
    "            \n",
    "        ## If either of the sections has zero length, report an error.\n",
    "        if len(start) == 0 or len(end) == 0:\n",
    "            print 'Section %s incorrectly defined! Skipping...' %sections[i]\n",
    "            errors.loc[len(errors)] = [doc_id, year, 'all', 'headers not defined']\n",
    "            continue\n",
    "        \n",
    "        ## Extract section counter, and remove small text.\n",
    "        content = visible_texts[start[0][0]:end[0][0]]\n",
    "        len_pre = len(content)\n",
    "        content_valid = [item for item in content if len(item) > 50]\n",
    "        \n",
    "        ## Checks for section length.\n",
    "        len_content = len(content_valid)\n",
    "        len_ratio = len_content / float(len_total)\n",
    "\n",
    "        if len_ratio == 0:\n",
    "            errors.loc[len(errors)] = [doc_id, year, sections[i], 'length zero']\n",
    "            print 'Section %s on year %s has zero length!!!' %(sections[i], year)\n",
    "            \n",
    "        elif len_ratio > 0.8:\n",
    "            errors.loc[len(errors)] = [doc_id, year, sections[i], 'length 80% of document']\n",
    "            print 'Section %s on year %s is more than 80% of the document.'\n",
    "        ## Add section to dictionary and log.\n",
    "        logs.loc[len(logs)] = [doc_id, year, sections[i], len_pre, len_content, len_ratio]\n",
    "        all_sections[sections[i]] = content_valid\n",
    "    all_docs[(doc_id, year)] = all_sections            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Zone\n",
    "To test the extraction of individual sections on specific documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009\n",
      "[[5083, u'Item 1A. Risk Factors']]\n",
      "[[5089, u'Item 1B. Unresolved Staff Comments']]\n"
     ]
    }
   ],
   "source": [
    "htmls = 'https://www.sec.gov/Archives/edgar/data/51143/000104746910001151/a2195966z10-k.htm'\n",
    "soup = BeautifulSoup(urllib2.urlopen(html).read(), 'html.parser')\n",
    "\n",
    "texts = soup.findAll(text=True)\n",
    "visible_texts = filter(visible, texts)\n",
    "\n",
    "## Check if year is extracted.\n",
    "year = [line for line in visible_texts if pattern_year.findall(line)][0].split(',')[-1].strip()\n",
    "print year\n",
    "\n",
    "sections = ['1A', '1B']\n",
    "i=0\n",
    "\n",
    "## Starting and ending patterns.\n",
    "pattern_start = re.compile(\"(\\s)?Item[(\\\\xa0)|(\\s)]?\" + sections[i] + \"\\.\")\n",
    "pattern_end = re.compile(\"(\\s)?Item[(\\\\xa0)|(\\s)]?\" + sections[i+1] + \"\\.\")\n",
    "\n",
    "## Try to get headers.\n",
    "start = [[s,line] for s,line in enumerate(visible_texts) if pattern_start.match(line)]\n",
    "end = [[e,line] for e,line in enumerate(visible_texts) if pattern_end.match(line)]\n",
    "\n",
    "print start\n",
    "print end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_sre.SRE_Match object at 0x7f9c3cf03300>\n"
     ]
    }
   ],
   "source": [
    "pattern_start = re.compile(\"(\\s)?Item[(\\\\xa0)|(\\s)]?\" + '1A' + \"\\.\", re.I)\n",
    "print pattern_start.match('ITEM 1A.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
